{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gensim.models import KeyedVectors\n",
    "from tqdm import tqdm \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogy_questions_path = \"../datasets/analogy_questions.txt\"\n",
    "restricted_vocab_path = \"../vocabs/final_vocab.pkl\"\n",
    "\n",
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"FastText\": \"../models/restricted/fasttext_300.vec\",\n",
    "    \"huBERT_x2\": \"../models/restricted/hubert.vec\",\n",
    "    \"EFNILEX\": \"../models/restricted/efnilex_600.vec\",\n",
    "    \"HuSpacy\": \"../models/restricted/huspacy.vec\",\n",
    "    \"XLM-R_x2\": \"../models/restricted/roberta.vec\",\n",
    "    \"ELMO\": \"../models/restricted/elmo_1024.vec\",\n",
    "    \"huBERT_de\": \"../models/restricted/hubert_decontex.vec\",\n",
    "    \"XLM-R_de\": \"../models/restricted/roberta_decontex.vec\",\n",
    "    \"XLM-R_agg\": \"../models/restricted/roberta_aggregate.vec\",\n",
    "    \"hubert_agg\": \"../models/restricted/hubert_aggregate.vec\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogy questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>word3</th>\n",
       "      <th>word4</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Budapest</td>\n",
       "      <td>Magyarország</td>\n",
       "      <td>Moszkva</td>\n",
       "      <td>Oroszország</td>\n",
       "      <td>capital-common-countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Budapest</td>\n",
       "      <td>Magyarország</td>\n",
       "      <td>London</td>\n",
       "      <td>Nagy-Britannia</td>\n",
       "      <td>capital-common-countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Budapest</td>\n",
       "      <td>Magyarország</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Németország</td>\n",
       "      <td>capital-common-countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Budapest</td>\n",
       "      <td>Magyarország</td>\n",
       "      <td>Pozsony</td>\n",
       "      <td>Szlovákia</td>\n",
       "      <td>capital-common-countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Budapest</td>\n",
       "      <td>Magyarország</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>Finnország</td>\n",
       "      <td>capital-common-countries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13245</th>\n",
       "      <td>vonatkoznak</td>\n",
       "      <td>vonatkozik</td>\n",
       "      <td>léteznek</td>\n",
       "      <td>létezik</td>\n",
       "      <td>gram9-plural-verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13246</th>\n",
       "      <td>vonatkoznak</td>\n",
       "      <td>vonatkozik</td>\n",
       "      <td>mutatnak</td>\n",
       "      <td>mutat</td>\n",
       "      <td>gram9-plural-verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13247</th>\n",
       "      <td>szólnak</td>\n",
       "      <td>szól</td>\n",
       "      <td>léteznek</td>\n",
       "      <td>létezik</td>\n",
       "      <td>gram9-plural-verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13248</th>\n",
       "      <td>szólnak</td>\n",
       "      <td>szól</td>\n",
       "      <td>mutatnak</td>\n",
       "      <td>mutat</td>\n",
       "      <td>gram9-plural-verb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13249</th>\n",
       "      <td>léteznek</td>\n",
       "      <td>létezik</td>\n",
       "      <td>mutatnak</td>\n",
       "      <td>mutat</td>\n",
       "      <td>gram9-plural-verb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13250 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word1         word2     word3           word4  \\\n",
       "0         Budapest  Magyarország   Moszkva     Oroszország   \n",
       "1         Budapest  Magyarország    London  Nagy-Britannia   \n",
       "2         Budapest  Magyarország    Berlin     Németország   \n",
       "3         Budapest  Magyarország   Pozsony       Szlovákia   \n",
       "4         Budapest  Magyarország  Helsinki      Finnország   \n",
       "...            ...           ...       ...             ...   \n",
       "13245  vonatkoznak    vonatkozik  léteznek         létezik   \n",
       "13246  vonatkoznak    vonatkozik  mutatnak           mutat   \n",
       "13247      szólnak          szól  léteznek         létezik   \n",
       "13248      szólnak          szól  mutatnak           mutat   \n",
       "13249     léteznek       létezik  mutatnak           mutat   \n",
       "\n",
       "                       category  \n",
       "0      capital-common-countries  \n",
       "1      capital-common-countries  \n",
       "2      capital-common-countries  \n",
       "3      capital-common-countries  \n",
       "4      capital-common-countries  \n",
       "...                         ...  \n",
       "13245         gram9-plural-verb  \n",
       "13246         gram9-plural-verb  \n",
       "13247         gram9-plural-verb  \n",
       "13248         gram9-plural-verb  \n",
       "13249         gram9-plural-verb  \n",
       "\n",
       "[13250 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load vocabulary\n",
    "with open(restricted_vocab_path, \"rb\") as file:\n",
    "    vocab = pickle.load(file)\n",
    "\n",
    "# Initialize DataFrame\n",
    "restricted_df = pd.DataFrame(columns=[\"word1\", \"word2\", \"word3\", \"word4\", \"category\"])\n",
    "original_df = pd.DataFrame(columns=[\"word1\", \"word2\", \"word3\", \"word4\", \"category\"])\n",
    "\n",
    "# Import analogy questions\n",
    "with open(analogy_questions_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    current_category = None  # Track category lines\n",
    "    \n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "\n",
    "        # Check if it's a category line (starts with \": \")\n",
    "        if line.startswith(\": \"):\n",
    "            current_category = line[2:].strip()\n",
    "            continue\n",
    "        \n",
    "        # Process analogy lines\n",
    "        words = line.split()\n",
    "        # Save in restricted_df if all words are in vocab and save all lines into original_df \n",
    "        if len(words) == 4 and all(word in vocab for word in words):  \n",
    "            w1, w2, w3, w4 = words\n",
    "            restricted_df = pd.concat([restricted_df, pd.DataFrame([{\n",
    "                \"word1\": w1, \"word2\": w2, \"word3\": w3, \"word4\": w4, \"category\": current_category\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "            original_df = pd.concat([original_df, pd.DataFrame([{\n",
    "                \"word1\": w1, \"word2\": w2, \"word3\": w3, \"word4\": w4, \"category\": current_category\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "        # Save out of vocab lines into original_df\n",
    "        elif len(words) == 4:\n",
    "            w1, w2, w3, w4 = words\n",
    "            original_df = pd.concat([original_df, pd.DataFrame([{\n",
    "                \"word1\": w1, \"word2\": w2, \"word3\": w3, \"word4\": w4, \"category\": current_category\n",
    "            }])], ignore_index=True)\n",
    "\n",
    "restricted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>original</th>\n",
       "      <th>restricted</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capital-common-countries</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capital-world</td>\n",
       "      <td>13695</td>\n",
       "      <td>5995</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>county-center</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>currency</td>\n",
       "      <td>435</td>\n",
       "      <td>406</td>\n",
       "      <td>93.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>family</td>\n",
       "      <td>190</td>\n",
       "      <td>136</td>\n",
       "      <td>71.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gram1-adjective-to-adverb</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gram2-opposite</td>\n",
       "      <td>435</td>\n",
       "      <td>435</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gram3-comparative</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gram4-superlative</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gram5-present-participle</td>\n",
       "      <td>780</td>\n",
       "      <td>496</td>\n",
       "      <td>63.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gram6-nationality-adjective</td>\n",
       "      <td>820</td>\n",
       "      <td>741</td>\n",
       "      <td>90.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gram8-plural-noun</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gram9-plural-verb</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       category  original  restricted  ratio\n",
       "0      capital-common-countries       190         190  100.0\n",
       "1                 capital-world     13695        5995   43.8\n",
       "2                 county-center       171         171  100.0\n",
       "3                      currency       435         406   93.3\n",
       "4                        family       190         136   71.6\n",
       "5     gram1-adjective-to-adverb       780         780  100.0\n",
       "6                gram2-opposite       435         435  100.0\n",
       "7             gram3-comparative       780         780  100.0\n",
       "8             gram4-superlative       780         780  100.0\n",
       "9      gram5-present-participle       780         496   63.6\n",
       "10  gram6-nationality-adjective       820         741   90.4\n",
       "11             gram7-past-tense       780         780  100.0\n",
       "12            gram8-plural-noun       780         780  100.0\n",
       "13            gram9-plural-verb       780         780  100.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = original_df.groupby(\"category\", as_index=False)['word1'].count().rename(columns={\"word1\": \"original\"})\n",
    "comp_df = temp_df.merge(restricted_df.groupby(\"category\", as_index=False)['word1'].count().rename(columns={\"word1\": \"restricted\"}))\n",
    "comp_df[\"ratio\"] = (comp_df[\"restricted\"] / comp_df[\"original\"] * 100).round(1)\n",
    "comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading models & running evaluations:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading FastText...\n",
      "Loaded FastText...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating FastText: 100%|██████████| 13250/13250 [02:49<00:00, 78.37it/s]\n",
      "Loading models & running evaluations:  10%|█         | 1/10 [03:18<29:43, 198.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading huBERT_x2...\n",
      "Loaded huBERT_x2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating huBERT_x2: 100%|██████████| 13250/13250 [04:57<00:00, 44.51it/s]\n",
      "Loading models & running evaluations:  20%|██        | 2/10 [09:32<40:12, 301.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading EFNILEX...\n",
      "Loaded EFNILEX...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating EFNILEX: 100%|██████████| 13250/13250 [04:15<00:00, 51.83it/s]\n",
      "Loading models & running evaluations:  30%|███       | 3/10 [14:42<35:38, 305.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading HuSpacy...\n",
      "Loaded HuSpacy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating HuSpacy: 100%|██████████| 13250/13250 [02:53<00:00, 76.16it/s]\n",
      "Loading models & running evaluations:  40%|████      | 4/10 [18:04<26:27, 264.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading XLM-R_x2...\n",
      "Loaded XLM-R_x2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating XLM-R_x2: 100%|██████████| 13250/13250 [04:57<00:00, 44.59it/s]\n",
      "Loading models & running evaluations:  50%|█████     | 5/10 [24:16<25:17, 303.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading ELMO...\n",
      "Loaded ELMO...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating ELMO: 100%|██████████| 13250/13250 [05:54<00:00, 37.33it/s]\n",
      "Loading models & running evaluations:  60%|██████    | 6/10 [31:46<23:33, 353.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading huBERT_de...\n",
      "Loaded huBERT_de...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating huBERT_de: 100%|██████████| 13250/13250 [04:54<00:00, 44.92it/s]\n",
      "Loading models & running evaluations:  70%|███████   | 7/10 [37:53<17:53, 357.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading XLM-R_de...\n",
      "Loaded XLM-R_de...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating XLM-R_de: 100%|██████████| 13250/13250 [04:45<00:00, 46.38it/s]\n",
      "Loading models & running evaluations:  80%|████████  | 8/10 [43:51<11:55, 357.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading XLM-R_agg...\n",
      "Loaded XLM-R_agg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating XLM-R_agg: 100%|██████████| 13250/13250 [04:46<00:00, 46.22it/s]\n",
      "Loading models & running evaluations:  90%|█████████ | 9/10 [49:49<05:57, 357.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading hubert_agg...\n",
      "Loaded hubert_agg...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating hubert_agg: 100%|██████████| 13250/13250 [04:34<00:00, 48.29it/s]\n",
      "Loading models & running evaluations: 100%|██████████| 10/10 [55:36<00:00, 333.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final MRR Results Across Models:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>FastText</th>\n",
       "      <th>huBERT_x2</th>\n",
       "      <th>EFNILEX</th>\n",
       "      <th>HuSpacy</th>\n",
       "      <th>XLM-R_x2</th>\n",
       "      <th>ELMO</th>\n",
       "      <th>huBERT_de</th>\n",
       "      <th>XLM-R_de</th>\n",
       "      <th>XLM-R_agg</th>\n",
       "      <th>hubert_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overall MRR</td>\n",
       "      <td>0.771571</td>\n",
       "      <td>0.584121</td>\n",
       "      <td>0.460185</td>\n",
       "      <td>0.459904</td>\n",
       "      <td>0.451567</td>\n",
       "      <td>0.223469</td>\n",
       "      <td>0.219142</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.230488</td>\n",
       "      <td>0.242267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Overall accuracy</td>\n",
       "      <td>0.709358</td>\n",
       "      <td>0.486717</td>\n",
       "      <td>0.389132</td>\n",
       "      <td>0.379472</td>\n",
       "      <td>0.371472</td>\n",
       "      <td>0.179623</td>\n",
       "      <td>0.169057</td>\n",
       "      <td>0.012604</td>\n",
       "      <td>0.179547</td>\n",
       "      <td>0.184604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capital-common-countries</td>\n",
       "      <td>0.769845</td>\n",
       "      <td>0.582982</td>\n",
       "      <td>0.454582</td>\n",
       "      <td>0.440090</td>\n",
       "      <td>0.398567</td>\n",
       "      <td>0.090551</td>\n",
       "      <td>0.168680</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.260253</td>\n",
       "      <td>0.250729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital-world</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>0.503311</td>\n",
       "      <td>0.284692</td>\n",
       "      <td>0.246899</td>\n",
       "      <td>0.299127</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.079138</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.170430</td>\n",
       "      <td>0.225653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>county-center</td>\n",
       "      <td>0.876218</td>\n",
       "      <td>0.761863</td>\n",
       "      <td>0.307069</td>\n",
       "      <td>0.467799</td>\n",
       "      <td>0.253973</td>\n",
       "      <td>0.089731</td>\n",
       "      <td>0.237220</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.074675</td>\n",
       "      <td>0.180286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>currency</td>\n",
       "      <td>0.305776</td>\n",
       "      <td>0.095262</td>\n",
       "      <td>0.194954</td>\n",
       "      <td>0.152957</td>\n",
       "      <td>0.084856</td>\n",
       "      <td>0.123101</td>\n",
       "      <td>0.068424</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.088254</td>\n",
       "      <td>0.065848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>family</td>\n",
       "      <td>0.655494</td>\n",
       "      <td>0.665625</td>\n",
       "      <td>0.397803</td>\n",
       "      <td>0.586076</td>\n",
       "      <td>0.456629</td>\n",
       "      <td>0.325925</td>\n",
       "      <td>0.295927</td>\n",
       "      <td>0.045781</td>\n",
       "      <td>0.249945</td>\n",
       "      <td>0.218175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gram1-adjective-to-adverb</td>\n",
       "      <td>0.631606</td>\n",
       "      <td>0.585044</td>\n",
       "      <td>0.367670</td>\n",
       "      <td>0.606313</td>\n",
       "      <td>0.776716</td>\n",
       "      <td>0.130213</td>\n",
       "      <td>0.248623</td>\n",
       "      <td>0.066223</td>\n",
       "      <td>0.264824</td>\n",
       "      <td>0.197808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gram2-opposite</td>\n",
       "      <td>0.434839</td>\n",
       "      <td>0.162315</td>\n",
       "      <td>0.285733</td>\n",
       "      <td>0.237040</td>\n",
       "      <td>0.171484</td>\n",
       "      <td>0.099909</td>\n",
       "      <td>0.074059</td>\n",
       "      <td>0.012874</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>0.013736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gram3-comparative</td>\n",
       "      <td>0.755579</td>\n",
       "      <td>0.812676</td>\n",
       "      <td>0.749232</td>\n",
       "      <td>0.744924</td>\n",
       "      <td>0.814748</td>\n",
       "      <td>0.469363</td>\n",
       "      <td>0.384272</td>\n",
       "      <td>0.096281</td>\n",
       "      <td>0.392271</td>\n",
       "      <td>0.295406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gram4-superlative</td>\n",
       "      <td>0.678811</td>\n",
       "      <td>0.624604</td>\n",
       "      <td>0.722378</td>\n",
       "      <td>0.592043</td>\n",
       "      <td>0.291509</td>\n",
       "      <td>0.272485</td>\n",
       "      <td>0.220006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.189042</td>\n",
       "      <td>0.211151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gram5-present-participle</td>\n",
       "      <td>0.548546</td>\n",
       "      <td>0.172274</td>\n",
       "      <td>0.107407</td>\n",
       "      <td>0.715035</td>\n",
       "      <td>0.119718</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.150886</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.022729</td>\n",
       "      <td>0.024451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gram6-nationality-adjective</td>\n",
       "      <td>0.912250</td>\n",
       "      <td>0.872561</td>\n",
       "      <td>0.683943</td>\n",
       "      <td>0.614656</td>\n",
       "      <td>0.642747</td>\n",
       "      <td>0.093128</td>\n",
       "      <td>0.218998</td>\n",
       "      <td>0.012230</td>\n",
       "      <td>0.374643</td>\n",
       "      <td>0.373578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gram7-past-tense</td>\n",
       "      <td>0.821526</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.952350</td>\n",
       "      <td>0.859873</td>\n",
       "      <td>0.906457</td>\n",
       "      <td>0.822359</td>\n",
       "      <td>0.486627</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>0.168932</td>\n",
       "      <td>0.180385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gram8-plural-noun</td>\n",
       "      <td>0.766537</td>\n",
       "      <td>0.608066</td>\n",
       "      <td>0.664177</td>\n",
       "      <td>0.676048</td>\n",
       "      <td>0.657216</td>\n",
       "      <td>0.664570</td>\n",
       "      <td>0.704163</td>\n",
       "      <td>0.063069</td>\n",
       "      <td>0.343413</td>\n",
       "      <td>0.278247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gram9-plural-verb</td>\n",
       "      <td>0.939359</td>\n",
       "      <td>0.970107</td>\n",
       "      <td>0.947033</td>\n",
       "      <td>0.873263</td>\n",
       "      <td>0.866218</td>\n",
       "      <td>0.860478</td>\n",
       "      <td>0.545058</td>\n",
       "      <td>0.015363</td>\n",
       "      <td>0.684679</td>\n",
       "      <td>0.667065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Category  FastText  huBERT_x2   EFNILEX   HuSpacy  \\\n",
       "0                   Overall MRR  0.771571   0.584121  0.460185  0.459904   \n",
       "1              Overall accuracy  0.709358   0.486717  0.389132  0.379472   \n",
       "2      capital-common-countries  0.769845   0.582982  0.454582  0.440090   \n",
       "3                 capital-world  0.833000   0.503311  0.284692  0.246899   \n",
       "4                 county-center  0.876218   0.761863  0.307069  0.467799   \n",
       "5                      currency  0.305776   0.095262  0.194954  0.152957   \n",
       "6                        family  0.655494   0.665625  0.397803  0.586076   \n",
       "7     gram1-adjective-to-adverb  0.631606   0.585044  0.367670  0.606313   \n",
       "8                gram2-opposite  0.434839   0.162315  0.285733  0.237040   \n",
       "9             gram3-comparative  0.755579   0.812676  0.749232  0.744924   \n",
       "10            gram4-superlative  0.678811   0.624604  0.722378  0.592043   \n",
       "11     gram5-present-participle  0.548546   0.172274  0.107407  0.715035   \n",
       "12  gram6-nationality-adjective  0.912250   0.872561  0.683943  0.614656   \n",
       "13             gram7-past-tense  0.821526   0.950000  0.952350  0.859873   \n",
       "14            gram8-plural-noun  0.766537   0.608066  0.664177  0.676048   \n",
       "15            gram9-plural-verb  0.939359   0.970107  0.947033  0.873263   \n",
       "\n",
       "    XLM-R_x2      ELMO  huBERT_de  XLM-R_de  XLM-R_agg  hubert_agg  \n",
       "0   0.451567  0.223469   0.219142  0.017782   0.230488    0.242267  \n",
       "1   0.371472  0.179623   0.169057  0.012604   0.179547    0.184604  \n",
       "2   0.398567  0.090551   0.168680  0.009649   0.260253    0.250729  \n",
       "3   0.299127  0.034469   0.079138  0.003213   0.170430    0.225653  \n",
       "4   0.253973  0.089731   0.237220  0.001462   0.074675    0.180286  \n",
       "5   0.084856  0.123101   0.068424  0.000821   0.088254    0.065848  \n",
       "6   0.456629  0.325925   0.295927  0.045781   0.249945    0.218175  \n",
       "7   0.776716  0.130213   0.248623  0.066223   0.264824    0.197808  \n",
       "8   0.171484  0.099909   0.074059  0.012874   0.040579    0.013736  \n",
       "9   0.814748  0.469363   0.384272  0.096281   0.392271    0.295406  \n",
       "10  0.291509  0.272485   0.220006  0.000000   0.189042    0.211151  \n",
       "11  0.119718  0.007700   0.150886  0.002923   0.022729    0.024451  \n",
       "12  0.642747  0.093128   0.218998  0.012230   0.374643    0.373578  \n",
       "13  0.906457  0.822359   0.486627  0.004701   0.168932    0.180385  \n",
       "14  0.657216  0.664570   0.704163  0.063069   0.343413    0.278247  \n",
       "15  0.866218  0.860478   0.545058  0.015363   0.684679    0.667065  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = {}\n",
    "\n",
    "def mean_reciprocal_rank(ranks):\n",
    "    \"\"\"\n",
    "    Computes the Mean Reciprocal Rank (MRR) given a list of ranks.\n",
    "    \"\"\"\n",
    "    return sum(1.0 / rank if rank > 0 else 0 for rank in ranks) / len(ranks) if ranks else 0\n",
    "\n",
    "def evaluate_analogy_model(model, model_name, analogy_df, vocab_file=restricted_vocab_path, category_counts=category_counts):\n",
    "    \"\"\"\n",
    "    Evaluates an embedding model on the analogy task and returns Mean Reciprocal Rank (MRR) per category.\n",
    "    \"\"\"\n",
    "    # Load vocabulary\n",
    "    with open(vocab_file, \"rb\") as file:\n",
    "        vocab = pickle.load(file)\n",
    "\n",
    "    overall_ranks = []\n",
    "    total_cases = 0\n",
    "    top1_correct = 0\n",
    "\n",
    "    # Perform analogy test\n",
    "    for _, row in tqdm(analogy_df.iterrows(), total=len(analogy_df), desc=f\"Evaluating {model_name}\"):\n",
    "        w1, w2, w3, actual_w4, category = row[\"word1\"], row[\"word2\"], row[\"word3\"], row[\"word4\"], row[\"category\"]\n",
    "\n",
    "        try:\n",
    "            predictions = model.most_similar(positive=[w3, w2], negative=[w1], topn=10)\n",
    "            predicted_words = [word for word, _ in predictions]\n",
    "\n",
    "            # Find rank of actual_w4 (1-based index, or 0 if not found)\n",
    "            rank = predicted_words.index(actual_w4) + 1 if actual_w4 in predicted_words else 0\n",
    "            overall_ranks.append(rank)\n",
    "            category_counts[category][\"ranks\"].append(rank)\n",
    "\n",
    "            if rank == 1:\n",
    "                top1_correct += 1\n",
    "\n",
    "            total_cases += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    # Compute overall MRR\n",
    "    overall_mrr = mean_reciprocal_rank(overall_ranks)\n",
    "    overall_acc = top1_correct / total_cases\n",
    "\n",
    "    # Create DataFrame\n",
    "    category_mrr_df = pd.DataFrame([\n",
    "        {\"Category\": cat, \n",
    "         model_name: mean_reciprocal_rank(data[\"ranks\"]) if data[\"ranks\"] else 0}\n",
    "        for cat, data in category_counts.items()\n",
    "    ])\n",
    "\n",
    "    # Append overall MRR\n",
    "    category_mrr_df = pd.concat([category_mrr_df, pd.DataFrame([{\"Category\": \"Overall MRR\", model_name: overall_mrr},{\"Category\": \"Overall accuracy\", model_name: overall_acc}])], ignore_index=True)\n",
    "    \n",
    "    return category_mrr_df\n",
    "\n",
    "# Run evaluations and merge results with tqdm\n",
    "final_df = None\n",
    "\n",
    "for model_name, model_path in tqdm(models.items(), desc=\"Loading models & running evaluations\"):\n",
    "    print(f\"\\nLoading {model_name}...\")\n",
    "    model = KeyedVectors.load_word2vec_format(model_path, binary=False)\n",
    "    print(f\"Loaded {model_name}...\")\n",
    "    for cat in restricted_df[\"category\"].unique():\n",
    "        category_counts[cat] = {\"ranks\": []}\n",
    "    result_df = evaluate_analogy_model(model, model_name, restricted_df)\n",
    "\n",
    "    if final_df is None:\n",
    "        final_df = result_df\n",
    "    else:\n",
    "        final_df = final_df.merge(result_df, on=\"Category\", how=\"outer\")\n",
    "\n",
    "# Display final results\n",
    "print(\"\\nFinal MRR Results Across Models:\")\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home_jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
